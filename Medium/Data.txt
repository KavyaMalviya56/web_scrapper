Faster analytics and smarter insights are the new ways to business and new way to cloud. As an example, I want to talk about just how many data points MLB captures with Google Cloud in a single game. Watch this video:Statcast is an analytics application that let’s you search MLB’s Statcast database. As you see in this video, there are so many attributes that go into analyzing a game and players. Together with MLB, Google Cloud captures and analyzes 15 million data points, in real time, every single game.The data points are used to derive insights in real time, like, catch probability, distance needed, win probability, perceived velocity, hit distance, spin rate, battled ball direction, quality of contact and so many more. Now I’m not going to discuss the analytics of the game further.I just wanted to bring to your attention just how important it is to deliver analytics and insights faster and in real time, for any business.One of the major challenges that organizations face in delivering such real time metrics is integrating services: either on the same cloud platform or products across platforms and more often than not, on-premise to cloud. Integrating analytics and other applications (for eg. a trained model endpoint) to your data, requires your endpoint to be invoked from where your data near real-time. In order to enable this integration, teams build complex solutions or end up compromising on performance.Integrating multiple services at high velocity to derive business and data insights with the help of serverless products is what we call programmable cloud.Giving you the ability to expose Cloud Functions as a remote function that can be invoked directly from BigQuery SQL, makes your application super-powerful, because you handle storage and insights in one place — exactly where your data resides!Let’s look at this with a hands-on example. In this hands-on we will create a Python Cloud Function to predict the success score of a movie based on 2 attributes: it’s GENRE and RUNTIME. This function will be invoked as a remote function in a BIGQUERY SQL to predict the success score for a movie stored in a BigQuery table.Let’s create a Python Cloud Function: Source code in repo. You can also see the main.py here for your reference, comments are pretty self-explanatory for each line of code:a. Open Cloud Shell Editorb. Create a new directory in the root, named “movie-score-remote”c. Open Cloud Shell Terminal and run below commands:c. This command should upload the all the files from the repo to your folder movie-score-remote — main.py, requirements.txt, movies_bq_src.csv and movies_bq_src_predict.csvDeploy Cloud Functiona. Open Cloud Shell Terminal and make sure you are still in the directory movie-score-remoteb. To deploy the CF, run:Create BigQuery Dataset, BigLake Connection and a Tablea. Create Dataset named “movies” in BigQuery in the region us-central1 by running the below command in Cloud Shell Terminal:b. Create an External Connection by clicking the ADD button on the top left corner of the BigQuery consolec. Click Connections to external data sources and select Connection Type as “BigLake and remote functions (cloud resource)”d. Provide the same region as the dataset (us-central1) and click CREATE DATASETe. Copy the Service Account in the Connection Configuration page and save it somewhere for later usef. Create a table and load data to be predicted: From the Cloud Shell Terminal, run below command:Create Remote Functionsa. Open Query Editor in BigQuery console and enter the following command to create the remote function:Predicta. Now that the model is created. you can use test your remote function. Run the following SQL query:b. You should see the result like this:Note:You have successfully predicted the score of a movie stored in BigQuery table using the model that you created in a Python program that is deployed as a Serverless Cloud Function!!! Read more in the documentation to implement this on a batch of records.As an exercise, try leveraging the power of BigQuery in handling unstructured data by extending this use case to include images or video snippets and unifying structured and unstructured data in a query for your insights and ML.